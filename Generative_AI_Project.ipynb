{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1f3TEqFhppq"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-OegMk7hkuI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "OPENAI_API_KEY = \"Private OPENAI Key\"\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLEE-PqQglPU"
      },
      "outputs": [],
      "source": [
        "def upload_file(file_path):\n",
        "\n",
        "\t# Upload a file with an \"assistants\" purpose\n",
        "\tfile_to_upload = client.files.create(\n",
        "  \tfile=open(file_path, \"rb\"),\n",
        "  \tpurpose='assistants'\n",
        "\t)\n",
        "     return file_to_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px34AmtAh4oj"
      },
      "outputs": [],
      "source": [
        "file_path = \"./data/xyz_file_path.pdf\"   #Insert the path of file that you want to upload\n",
        "file_to_upload = upload_file(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37adhTB5iSlW"
      },
      "outputs": [],
      "source": [
        "def create_assistant(assistant_name ,my_instruction ,uploaded_file ,model=\"gpt-4-1106-preview\"):\n",
        "  #Creating Assistant\n",
        "\tmy_assistant = client.beta.assistants.create(\n",
        "\tname = assistant_name,\n",
        "\tinstructions = my_instruction,\n",
        "\tmodel=\"gpt-4-1106-preview\",\n",
        "\ttools=[{\"type\": \"retrieval\"}],\n",
        "\tfile_ids=[uploaded_file.id]\n",
        "\t)\n",
        "\n",
        "\treturn my_assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnlwqMYHi8FG"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "You are Generative AI Assistant. Create a personalized study plan based on the following data:\n",
        "\n",
        "1. Subjects and Academic Performance:\n",
        "   - Subjects and grades/performance levels\n",
        "\n",
        "2. Preferred Learning Styles:\n",
        "   - Visual, Auditory, Kinesthetic\n",
        "\n",
        "3. Extracurricular Activities:\n",
        "   - List of activities\n",
        "\n",
        "4. Personal Objectives or Challenges:\n",
        "   - Exams, learning difficulties, personal goals\n",
        "\n",
        "Include in the study plan:\n",
        "\n",
        "- Weekly study schedule\n",
        "- Study techniques and resources for the learning style\n",
        "- Balance strategies for academics and activities\n",
        "- Action steps for objectives and challenges\n",
        "- Motivational tips\n",
        "\n",
        "Ensure the plan is realistic, achievable, and tailored to the student's unique needs. Present it clearly and structured.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDthCdm3isKJ"
      },
      "outputs": [],
      "source": [
        "assistant_name=\"Generative AI Assistant \"\n",
        "\n",
        "my_assistant = create_assistant(assistant_name, prompt_template, file_to_upload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ2bLY4-jlBa"
      },
      "outputs": [],
      "source": [
        "def initiate_interaction(user_message, uploaded_file):\n",
        "    \"\"\"The code defines a function initiate_interaction that takes user_message and uploaded_file as parameters. It performs the following steps:\n",
        "        Creates a new thread (my_thread) using client.beta.threads.create().\n",
        "        Sends a message in the thread using client.beta.threads.messages.create() with the thread ID, sender's role, message content, and uploaded file ID.\n",
        "        Returns my_thread.\"\"\"\n",
        "    my_thread = client.beta.threads.create()\n",
        "    message = client.beta.threads.messages.create(thread_id=my_thread.id,\n",
        "                                              \trole=\"user\",\n",
        "                                              \tcontent=user_message,\n",
        "                                              \tfile_ids=[uploaded_file.id]\n",
        "\t)\n",
        "    return my_thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScDqbu0pjqCh"
      },
      "outputs": [],
      "source": [
        "user_message = \"\"\"Generate a concise summary of the book \"Crime and Punishment\" limited to 20 pages.\"\"\"\n",
        "my_thread = initiate_interaction(user_message, file_to_upload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJeIiXw5jvzq"
      },
      "outputs": [],
      "source": [
        "def trigger_assistant():\n",
        "\trun = client.beta.threads.runs.create(\n",
        "  \tthread_id = my_thread.id,\n",
        "  \tassistant_id = my_assistant.id,\n",
        "\t)\n",
        "trigger_assistant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPai_KPKkJwd"
      },
      "outputs": [],
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id = my_thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itcaZOS8kLs_"
      },
      "outputs": [],
      "source": [
        "response = messages.data[0].content[0].text.value\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTgvsT1_lMZa"
      },
      "outputs": [],
      "source": [
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSGmbyxUk8iS"
      },
      "outputs": [],
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "def save_text_to_pdf(text, file_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.multi_cell(0, 10, text)\n",
        "\n",
        "    pdf.output(file_path)\n",
        "\n",
        "\n",
        "file_path = \"output.pdf\"\n",
        "save_text_to_pdf(response, file_path)\n",
        "\n",
        "print(f\"PDF saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"NOTE \n",
        "We offer two options for providing a file to the assistant. The first option is to provide the file directly during the creation of the assistant. The second option is to provide the file in a thread when the user submits a query.\n",
        "\n",
        "The key outcomes are:\n",
        "\n",
        "Providing the file ID during assistant creation: This approach generates an assistant specific to that particular file. However, it requires creating multiple assistants for different files, leading to higher costs and limitations.\n",
        "Providing the assistant ID and file ID in a thread: This method is more efficient and cost-effective, as a single assistant can handle the entire project.\n",
        "\n",
        "Choosing the second option saves costs and allows one assistant to manage the whole project effectively.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
